---
title: "main"
output: html_document
date: "2023-04-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mice)
library(dplyr)
library(tidyr)
library(jsonlite)
library(tidytext)
library(stringr)
library(dplyr)
library(psych)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(corrplot)
```

# Load Data
```{r}
data_dir <- "../data/"
listing <- read.csv(paste0(data_dir,"listings.csv"))
listing2 <- read.csv(paste0(data_dir, "listings 2.csv"))
neighbourhoods <- read.csv(paste0(data_dir, "neighbourhoods.csv"))
reviews <- read.csv(paste0(data_dir, "reviews.csv"))
reviews2 <- read.csv(paste0(data_dir, "reviews 2.csv"))

#listing <- read.csv(paste0("/Users/loganheft/Desktop/data-2/listings.csv"))
#listing2 <- read.csv(paste0("/Users/loganheft/Desktop/data-2/listings 2.csv"))
#neighbourhoods <- read.csv(paste0("/Users/loganheft/Desktop/data-2/neighbourhoods.csv"))
#reviews <- read.csv(paste0("/Users/loganheft/Desktop/data-2/reviews.csv"))
#reviews2 <- read.csv(paste0("/Users/loganheft/Desktop/data-2/reviews 2.csv"))

```
Our data covers the quarterly data from 2022.

# Data Preparation
``` {r}
# Select relevant features
listing_col <- c("id", "neighbourhood_group", "neighbourhood", "latitude", "longitude", "room_type", "price")
listing2_col <- c("id", "property_type", "accommodates", "bedrooms", "beds", "amenities", "review_scores_rating",
                  "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", 
                  "review_scores_location", "review_scores_value", "instant_bookable")
listing_sub <- subset(listing, select=listing_col)
listing2_sub <- subset(listing2,select=listing2_col)

# Merge listing and listing2
data <- merge(listing_sub, listing2_sub, by = "id", all.x = TRUE)

# Check for missing values
print("Missing values:")
colSums(is.na(data))
```
There some missing values, especially in the ratings variables. We will use MICE imputation to impute the missing values.
``` {r}

# Select variables with missing values
vars <- c("bedrooms", "beds", "review_scores_rating", "review_scores_accuracy", 
          "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", 
          "review_scores_location", "review_scores_value")

# Perform MICE imputation
imp <- mice(data[, vars], method = "pmm", m = 5, maxit = 50, seed = 12)


# Replace the missing values in the original dataset with the imputed values
data[, vars] <- complete(imp)

# Check for any remaining missing values
sapply(data, function(x) sum(is.na(x)))

```


```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(fuzzyjoin)

# Save the dataframe to a CSV file
write.csv(data, "imputed_data.csv", row.names = FALSE)

# Function to clean the column names
clean_colnames <- function(x) {
  x <- tolower(x)
  x <- str_remove_all(x, "[[:punct:]]")
  x
}

# Read the CSV file
df <- read.csv("imputed_data.csv")
df <- head(df)

# Convert instant_bookable to a binary numeric column
#df$instant_bookable <- ifelse(df$instant_bookable == "t", 1, 0)

# Create dummy variables for categorical columns
cat_columns <- c("neighbourhood_group", "neighbourhood", "room_type", "property_type")

for (col_name in cat_columns) {
  dummy_matrix <- model.matrix(~ 0 + ., data = df[col_name])
  colnames(dummy_matrix) <- gsub("^[^:]+:([^:]+)$", paste0(col_name, "_", "\\1"), colnames(dummy_matrix))
  df <- cbind(df, dummy_matrix)
  df[[col_name]] <- NULL
}

review_columns <- c("review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness","review_scores_checkin","review_scores_communication", "review_scores_location", "review_scores_value")

df[review_columns] <- apply(df[review_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))

# Clean amenities and create binary columns for each amenit
# Clean amenities and create binary columns for each amenity
df <- df %>%
  mutate(amenities = str_remove_all(amenities, "\\[|\\]|\"")) %>%
  separate_rows(amenities, sep = ", ") %>%
  mutate(amenity_clean = clean_colnames(amenities)) %>%
  mutate(amenities = paste0("amenity_", amenity_clean),
         amenities = ifelse(substr(amenities, 1, 10) == "amenity__", substr(amenities, 10), amenities),
         value = 1) %>%
  distinct(id, amenities, .keep_all = TRUE) %>%
  select(-amenity_clean)

#unique amenitites
amenities_wide_df <- df %>% pivot_wider(names_from = amenities, values_from = value, values_fill = 0)

df <-  amenities_wide_df
# Select columns that start with "amenity_"
amenity_cols <- grep("^amenity_", names(df), value = TRUE)

amenity_df <- df %>%
  select(id, amenity_cols) %>%
  rename_at(vars(-id), ~sub("amenity_", "", .))


```


#Preprocessing
```{r}
# Load required packages
# Read the data
data <- amenity_df

# Define a function to check if two columns contain a common word
has_common_word <- function(x, y) {
  x_words <- unlist(strsplit(names(data)[x], " "))
  y_words <- unlist(strsplit(names(data)[y], " "))
  any(x_words %in% y_words)
}


# Replace spaces and other characters with underscores in column names
names(data)[-1] <- gsub("[[:punct:] ]+", "_", names(data)[-1])


# Identify similar column pairs
similar_pairs <- combn(ncol(data), 2, FUN = function(x) {
  c(col1 = x[1], col2 = x[2], has_common_word(x[1], x[2]))
}) %>% 
  t() %>% 
  as.data.frame() %>% 
  set_names(c("col1", "col2", "similar")) %>% 
  mutate(similar = as.logical(similar)) %>% 
  filter(similar) %>% 
  select(-similar)


# Combine similar columns
for (i in seq_len(nrow(similar_pairs))) {
  col1 <- names(data)[similar_pairs$col1[i]]
  col2 <- names(data)[similar_pairs$col2[i]]
  new_col <- paste0(col1, "_", col2)
  data <- unite(data, new_col, col1, col2, sep = "_")
  data <- data %>% select(-c(col1, col2))
  print(paste0("Combined columns ", col1, " and ", col2, " into ", new_col))
}


# View updated data
data



```


#EDA
``` {r}
data <- data %>%
  filter(price < quantile(price, 0.99))

# Summarize the numerical variables
summary(data$price)
summary(data$review_scores_rating)

# Plot the distribution of the price variable
ggplot(data, aes(price)) + 
  geom_histogram() + 
  xlim(0, 3000)

ggplot(data, aes(price)) + 
  geom_histogram() + 
  xlim(0, 500)

# Plot the relationship between price and number of bedrooms
ggplot(data, aes(x = bedrooms, y = price)) + 
  geom_point()

# Show the average price for the top 20 most popular property types and sort the plot
top_property_types <- data %>% 
  group_by(property_type) %>% 
  summarize(num_properties = n()) %>% 
  top_n(20, num_properties)

data %>% 
  filter(property_type %in% top_property_types$property_type) %>% 
  group_by(property_type) %>% 
  summarize(avg_price = mean(price)) %>% 
  arrange(desc(avg_price)) %>% # Sort by average price in descending order
  ggplot(aes(x = property_type, y = avg_price)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Property Type", y = "Average Price")

# Get the top 20 neighborhoods by average price
top_neighborhoods <- data %>% 
  group_by(neighbourhood) %>% 
  summarize(avg_price = mean(price)) %>% 
  top_n(20, avg_price)

data %>% 
  filter(neighbourhood %in% top_neighborhoods$neighbourhood) %>% 
  group_by(neighbourhood) %>% 
  summarize(avg_price = mean(price)) %>% 
  ggplot(aes(x = reorder(neighbourhood, -avg_price), y = avg_price)) +
  geom_col() +
  coord_flip() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm")) +
  labs(x = "Neighborhood", y = "Average Price")

# Create a new variable for the month of the year
data$month <- month(ymd(data$last_review))

# Plot the number of reviews by month
data %>% 
  group_by(month) %>% 
  summarize(num_reviews = n()) %>% 
  ggplot(aes(x = month, y = num_reviews)) +
  geom_line() +
  scale_x_continuous(breaks = 1:12, labels = month.abb)
```


``` {r}

```

```{r}
# Load the necessary libraries and read in the data
data <- read.csv("path/to/airbnb/dataset.csv")

# Remove outliers
data <- data %>%
  filter(price < quantile(price, 0.99))

# Perform a linear regression to predict price
#If somebody wants to do some preprocessing of the data then we can use more factors
#I only wrote the code for the initial leg work


model <- lm(price ~ accommodates + bedrooms + review_scores_rating, data = data)
summary(model)

data <- na.omit(data)

# Perform a principal component analysis
pca <- prcomp(data[,c("accommodates", "bedrooms", "review_scores_rating")], center = TRUE, scale. = TRUE)

summary(pca)

plot(pca)

#principal components
pca$rotation

# principal component scores for each observation
pca$x

fa_result <- factanal(data[,c("accommodates", "bedrooms", "review_scores_rating")], factors = 1, rotation = "varimax")

#factor loadings
print(fa_result$loadings)

```


```{r}

```

```{r}

```
